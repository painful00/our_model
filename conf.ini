[General]
learning_rate = 0.01
weight_decay = 0.0001
dropout = 0.2
seed =0
hidden_dim = 64
max_epoch = 50
patience = 50
mini_batch_flag = False

[Augmentation]
embedding_size = 64
latent_size = 16
argmentation_type = ["author", "subject"]
argmentation_num = 3
is_augmentation = True
pretrain_lr = 0.01
pretrain_epochs = 10
batch_size = 64
resolution = 1000
threshold_sba = 0.1
threshold_usvt = 0.1
alpha = 0.0003
beta = 5e-3
gamma = 0.1
inner_iters = 50
outer_iters = 20
n_trials = 1
argmentation_path = ["MAM", "MDM"]
argmentation_intra_graph_num = 1
argmentation_inter_graph_num = 0

[HAN]
seed = 0
learning_rate = 0.005
weight_decay = 0.001
dropout = 0.6
hidden_dim = 128
out_dim = 16
num_heads = 8
max_epoch = 300
patience = 100
mini_batch_flag = False

[MAGNN]
seed = 0
learning_rate = 0.005
weight_decay = 0.001
dropout = 0.5
h_dim = 64
out_dim = 3
inter_attn_feats = 128
num_heads = 8
num_layers = 2
max_epoch = 1000
patience = 100
encoder_type = RotateE
mini_batch_flag = False
batch_size = 8
num_samples = 5

[SimpleHGN]
h_dim = 32
n_layers = 3
num_heads = 8
feats_drop_rate = 0.5
slope = 0.05
edge_dim = 64
seed = 0
max_epoch = 1000
patience = 50
lr = 0.001
weight_decay = 5e-4
beta = 0.05
residual = True


[HGT]
seed = 0
learning_rate = 0.001
weight_decay = 0.0001
dropout = 0.4
batch_size = 5120
patience =50
hidden_dim = 128
out_dim = 16
num_layers = 3
num_heads = 8
num_workers = 64
max_epoch = 1000
mini_batch_flag = False
norm = True


[HPN]
seed = 0
learning_rate = 0.005
weight_decay = 0.001
dropout = 0.6
k_layer = 2
alpha = 0.1
edge_drop = 0.4
hidden_dim = 64
out_dim = 16
max_epoch = 200
patience = 100
mini_batch_flag = False


[CompGCN]
learning_rate = 0.01
weight_decay = 0.0001
dropout = 0.5
seed = 0
n_layers = 3
in_dim = 32
hidden_dim = 128
out_dim = 32
max_epoch = 200
patience = 100
comp_fn = sub
validation = True
mini_batch_flag = False